{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8287c6",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 01 ¬∑ Notebook 03 ‚Äî Data Wrangling & Transformation\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master real-world data manipulation techniques.\n",
    "\n",
    "> Format: practical scenarios ‚Üí powerful pandas methods ‚Üí data ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Real Data is Messy!\n",
    "Let's load and clean actual messy data - the skills you'll use every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set display options for better visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "print(\"Ready to wrangle! üõ†Ô∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f40a1",
   "metadata": {},
   "source": [
    "## 1. Reading Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0037003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample CSV data (simulating a file)\n",
    "csv_data = \"\"\"order_id,customer_name,product,quantity,price,order_date\n",
    "1001,Alice Smith,Laptop,1,1200.00,2025-08-15\n",
    "1002,Bob Jones,Mouse,2,25.50,2025-08-15\n",
    "1003,Charlie Brown,,1,80.00,2025-08-16\n",
    "1004,Alice Smith,Monitor,1,,2025-08-16\n",
    "1005,Diana Prince,Keyboard,3,75.00,2025-08-17\n",
    "1006,,Webcam,1,120.00,2025-08-17\n",
    "1007,Bob Jones,Laptop,1,1200,2025-08-18\"\"\"\n",
    "\n",
    "# Save to file and read back\n",
    "with open('orders.csv', 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "# Read CSV with proper data types\n",
    "orders_df = pd.read_csv('orders.csv', parse_dates=['order_date'])\n",
    "print(\"Raw data from CSV:\")\n",
    "print(orders_df)\n",
    "print(f\"\\nData types:\")\n",
    "print(orders_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(orders_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c1c71",
   "metadata": {},
   "source": [
    "## 2. Cleaning Missing and Incorrect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy for cleaning\n",
    "clean_df = orders_df.copy()\n",
    "\n",
    "# Handle missing customer names\n",
    "clean_df['customer_name'].fillna('Unknown Customer', inplace=True)\n",
    "\n",
    "# Handle missing products (look at other orders from same customer)\n",
    "clean_df.loc[2, 'product'] = 'Keyboard'  # Reasonable guess based on price\n",
    "\n",
    "# Handle missing prices (use average for that product)\n",
    "monitor_avg_price = 350.00  # Domain knowledge\n",
    "clean_df.loc[3, 'price'] = monitor_avg_price\n",
    "\n",
    "# Ensure price is float\n",
    "clean_df['price'] = pd.to_numeric(clean_df['price'], errors='coerce')\n",
    "\n",
    "# Calculate total\n",
    "clean_df['total'] = clean_df['quantity'] * clean_df['price']\n",
    "\n",
    "print(\"Cleaned data:\")\n",
    "print(clean_df)\n",
    "print(f\"\\nRevenue by customer:\")\n",
    "print(clean_df.groupby('customer_name')['total'].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265e60a",
   "metadata": {},
   "source": [
    "**Exercise 1 ‚Äî Data Quality Check (medium)**  \n",
    "Create a function that returns a data quality report: % complete, unique counts, and outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25302",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "def data_quality_report(df):\n",
    "    report = {}\n",
    "    \n",
    "    # Completeness\n",
    "    report['completeness'] = (1 - df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Unique counts\n",
    "    report['unique_counts'] = df.nunique()\n",
    "    \n",
    "    # Outliers for numeric columns (using IQR)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers = {}\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers[col] = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()\n",
    "    report['outliers'] = outliers\n",
    "    \n",
    "    return report\n",
    "\n",
    "quality_report = data_quality_report(clean_df)\n",
    "print(\"Data Quality Report:\")\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(value)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91af14",
   "metadata": {},
   "source": [
    "## 3. Merging and Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create related dataframes\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice Smith', 'Bob Jones', 'Charlie Brown', 'Diana Prince'],\n",
    "    'city': ['Perth', 'Sydney', 'Melbourne', 'Brisbane'],\n",
    "    'member_since': ['2023-01-15', '2023-06-20', '2024-02-10', '2024-08-01']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 2, 1, 3, 1],\n",
    "    'amount': [150, 250, 100, 300, 175],\n",
    "    'date': pd.date_range('2025-08-20', periods=5)\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)\n",
    "\n",
    "# Merge dataframes\n",
    "merged = pd.merge(orders, customers, on='customer_id', how='left')\n",
    "print(\"\\nMerged data:\")\n",
    "print(merged)\n",
    "\n",
    "# Different join types\n",
    "print(\"\\nInner join (only matching):\")\n",
    "inner_join = pd.merge(orders, customers, on='customer_id', how='inner')\n",
    "print(f\"Rows: {len(inner_join)}\")\n",
    "\n",
    "print(\"\\nOuter join (all records):\")\n",
    "outer_join = pd.merge(orders, customers, on='customer_id', how='outer', indicator=True)\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1848",
   "metadata": {},
   "source": [
    "## 4. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sales data\n",
    "sales = pd.DataFrame({\n",
    "    'date': pd.date_range('2025-08-01', periods=20),\n",
    "    'store': np.random.choice(['Store_A', 'Store_B', 'Store_C'], 20),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet'], 20),\n",
    "    'quantity': np.random.randint(1, 10, 20),\n",
    "    'revenue': np.random.randint(100, 2000, 20)\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales.head(10))\n",
    "\n",
    "# Group by store\n",
    "store_summary = sales.groupby('store').agg({\n",
    "    'quantity': 'sum',\n",
    "    'revenue': ['sum', 'mean', 'count']\n",
    "})\n",
    "print(\"\\nStore summary:\")\n",
    "print(store_summary)\n",
    "\n",
    "# Multiple grouping\n",
    "product_store = sales.groupby(['product', 'store'])['revenue'].sum().unstack(fill_value=0)\n",
    "print(\"\\nRevenue by product and store:\")\n",
    "print(product_store)\n",
    "\n",
    "# Add calculated columns\n",
    "sales['revenue_per_unit'] = sales['revenue'] / sales['quantity']\n",
    "sales['day_of_week'] = sales['date'].dt.day_name()\n",
    "\n",
    "# Group by day of week\n",
    "daily_pattern = sales.groupby('day_of_week')['revenue'].mean().round(2)\n",
    "print(\"\\nAverage revenue by day:\")\n",
    "print(daily_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c85c5e",
   "metadata": {},
   "source": [
    "**Exercise 2 ‚Äî Customer Segmentation (hard)**  \n",
    "Group customers by total spend into segments: VIP (>500), Regular (200-500), New (<200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f39466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbd6b9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Calculate customer totals\n",
    "customer_totals = merged.groupby('name')['amount'].sum().reset_index()\n",
    "customer_totals.columns = ['customer', 'total_spend']\n",
    "\n",
    "# Create segments\n",
    "def segment_customer(spend):\n",
    "    if spend > 500: return 'VIP'\n",
    "    elif spend >= 200: return 'Regular'\n",
    "    else: return 'New'\n",
    "\n",
    "customer_totals['segment'] = customer_totals['total_spend'].apply(segment_customer)\n",
    "\n",
    "print(\"Customer segments:\")\n",
    "print(customer_totals.sort_values('total_spend', ascending=False))\n",
    "\n",
    "# Segment summary\n",
    "print(\"\\nSegment distribution:\")\n",
    "print(customer_totals['segment'].value_counts())\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3255a",
   "metadata": {},
   "source": [
    "## 5. Pivoting and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54870cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long format data\n",
    "long_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2025-08-01', periods=12),\n",
    "    'metric': ['Sales', 'Costs', 'Profit'] * 4,\n",
    "    'value': np.random.randint(1000, 5000, 12)\n",
    "})\n",
    "\n",
    "print(\"Long format:\")\n",
    "print(long_data)\n",
    "\n",
    "# Pivot to wide format\n",
    "wide_data = long_data.pivot(index='date', columns='metric', values='value')\n",
    "print(\"\\nWide format (pivoted):\")\n",
    "print(wide_data.head())\n",
    "\n",
    "# Melt back to long format\n",
    "melted = wide_data.reset_index().melt(id_vars='date', var_name='metric', value_name='amount')\n",
    "print(\"\\nMelted back to long:\")\n",
    "print(melted.head())\n",
    "\n",
    "# Pivot table with aggregation\n",
    "pivot_table = sales.pivot_table(\n",
    "    values='revenue',\n",
    "    index='store',\n",
    "    columns='product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True\n",
    ")\n",
    "print(\"\\nPivot table with totals:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93813ac",
   "metadata": {},
   "source": [
    "## 6. String Operations and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create messy text data\n",
    "contacts = pd.DataFrame({\n",
    "    'name': ['  john smith  ', 'JANE DOE', 'Bob Johnson Jr.', 'alice wong'],\n",
    "    'email': ['John.Smith@GMAIL.com', 'jane@company.COM', 'bob@email.co', 'Alice@Email.net'],\n",
    "    'phone': ['0412-345-678', '(04) 9876 5432', '0401234567', '04 1111 2222']\n",
    "})\n",
    "\n",
    "print(\"Messy contact data:\")\n",
    "print(contacts)\n",
    "\n",
    "# Clean strings\n",
    "contacts['name_clean'] = contacts['name'].str.strip().str.title()\n",
    "contacts['email_clean'] = contacts['email'].str.lower()\n",
    "\n",
    "# Extract domain from email\n",
    "contacts['domain'] = contacts['email_clean'].str.split('@').str[1]\n",
    "\n",
    "# Standardize phone numbers\n",
    "contacts['phone_clean'] = contacts['phone'].str.replace(r'[^0-9]', '', regex=True)\n",
    "\n",
    "print(\"\\nCleaned contacts:\")\n",
    "print(contacts[['name_clean', 'email_clean', 'phone_clean', 'domain']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98963a",
   "metadata": {},
   "source": [
    "## 7. Date and Time Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data\n",
    "dates = pd.date_range('2025-01-01', periods=100, freq='D')\n",
    "ts_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': np.random.randint(1000, 5000, 100) + \n",
    "             np.sin(np.arange(100) * 2 * np.pi / 30) * 500  # Add seasonality\n",
    "})\n",
    "\n",
    "# Extract date components